{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Art Style Transfer\n",
    "\n",
    "This notebook is an implementation of the algorithm described in \"A Neural Algorithm of Artistic Style\" (http://arxiv.org/abs/1508.06576) by Gatys, Ecker and Bethge. Additional details of their method are available at http://arxiv.org/abs/1505.07376 and http://bethgelab.org/deepneuralart/.\n",
    "\n",
    "An image is generated which combines the content of a photograph with the \"style\" of a painting. This is accomplished by jointly minimizing the squared difference between feature activation maps of the photo and generated image, and the squared difference of feature correlation between painting and generated image. A total variation penalty is also applied to reduce high frequency noise. \n",
    "\n",
    "This notebook was originally sourced from [Lasagne Recipes](https://github.com/Lasagne/Recipes/tree/master/examples/styletransfer), but has been modified to use a GoogLeNet network (pre-trained and pre-loaded), and given some features to make it easier to experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os # for directory listings\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "AS_PATH='./images/art-style'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import googlenet\n",
    "\n",
    "net = googlenet.build_model()\n",
    "net_input_var = net['input'].input_var\n",
    "net_output_layer = net['prob']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the pretrained weights into the network :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = pickle.load(open('./data/googlenet/blvc_googlenet.pkl'))\n",
    "model_param_values = params['param values']\n",
    "#classes = params['synset words']\n",
    "lasagne.layers.set_all_param_values(net_output_layer, model_param_values)\n",
    "\n",
    "IMAGE_W=224\n",
    "print(\"Loaded Model parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Choose the Photo to be *Enhanced*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "photos = [ '%s/photos/%s' % (AS_PATH, f) for f in os.listdir('%s/photos/' % AS_PATH) if not f.startswith('.')]\n",
    "photo_i=-1 # will be incremented in next cell (i.e. to start at [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the cell below will iterate through the images in the ```./images/art-style/photos``` directory, so you can choose the one you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "photo_i += 1\n",
    "photo = plt.imread(photos[photo_i % len(photos)])\n",
    "photo_rawim, photo = googlenet.prep_image(photo)\n",
    "plt.imshow(photo_rawim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the photo with the required 'Style'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "styles = [ '%s/styles/%s' % (AS_PATH, f) for f in os.listdir('%s/styles/' % AS_PATH) if not f.startswith('.')]\n",
    "style_i=-1 # will be incremented in next cell (i.e. to start at [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the cell below will iterate through the images in the ```./images/art-style/styles``` directory, so you can choose the one you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "style_i += 1\n",
    "art = plt.imread(styles[style_i % len(styles)])\n",
    "art_rawim, art = googlenet.prep_image(art)\n",
    "plt.imshow(art_rawim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines various measures of difference that we'll use to compare the current output image with the original sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_layout(combined):\n",
    "    def no_axes():\n",
    "        plt.gca().xaxis.set_visible(False)    \n",
    "        plt.gca().yaxis.set_visible(False)    \n",
    "        \n",
    "    plt.figure(figsize=(9,6))\n",
    "\n",
    "    plt.subplot2grid( (2,3), (0,0) )\n",
    "    no_axes()\n",
    "    plt.imshow(photo_rawim)\n",
    "\n",
    "    plt.subplot2grid( (2,3), (1,0) )\n",
    "    no_axes()\n",
    "    plt.imshow(art_rawim)\n",
    "\n",
    "    plt.subplot2grid( (2,3), (0,1), colspan=2, rowspan=2 )\n",
    "    no_axes()\n",
    "    plt.imshow(combined, interpolation='nearest')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    x = x.flatten(ndim=3)\n",
    "    g = T.tensordot(x, x, axes=([2], [2]))\n",
    "    return g\n",
    "\n",
    "def content_loss(P, X, layer):\n",
    "    p = P[layer]\n",
    "    x = X[layer]\n",
    "    \n",
    "    loss = 1./2 * ((x - p)**2).sum()\n",
    "    return loss\n",
    "\n",
    "def style_loss(A, X, layer):\n",
    "    a = A[layer]\n",
    "    x = X[layer]\n",
    "    \n",
    "    A = gram_matrix(a)\n",
    "    G = gram_matrix(x)\n",
    "    \n",
    "    N = a.shape[1]\n",
    "    M = a.shape[2] * a.shape[3]\n",
    "    \n",
    "    loss = 1./(4 * N**2 * M**2) * ((G - A)**2).sum()\n",
    "    return loss\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    return (((x[:,:,:-1,:-1] - x[:,:,1:,:-1])**2 + (x[:,:,:-1,:-1] - x[:,:,:-1,1:])**2)**1.25).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the GoogLeNet layers that we're going to pay attention to :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    # used for 'content' in photo - a mid-tier convolutional layer \n",
    "    'inception_4b/output', \n",
    "    \n",
    "    # used for 'style' - conv layers throughout model (not same as content one)\n",
    "    'conv1/7x7_s2', 'conv2/3x3', 'inception_3b/output', 'inception_4d/output',\n",
    "]\n",
    "#layers = [\n",
    "#    # used for 'content' in photo - a mid-tier convolutional layer \n",
    "#    'pool4/3x3_s2', \n",
    "#    \n",
    "#    # used for 'style' - conv layers throughout model (not same as content one)\n",
    "#    'conv1/7x7_s2', 'conv2/3x3', 'pool3/3x3_s2', 'inception_5b/output',\n",
    "#]\n",
    "layers = {k: net[k] for k in layers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precompute layer activations for photo and artwork \n",
    "This takes ~ 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_im_theano = T.tensor4()\n",
    "outputs = lasagne.layers.get_output(layers.values(), input_im_theano)\n",
    "\n",
    "photo_features = {k: theano.shared(output.eval({input_im_theano: photo}))\n",
    "                  for k, output in zip(layers.keys(), outputs)}\n",
    "art_features = {k: theano.shared(output.eval({input_im_theano: art}))\n",
    "                for k, output in zip(layers.keys(), outputs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get expressions for layer activations for generated image\n",
    "generated_image = theano.shared(floatX(np.random.uniform(-128, 128, (1, 3, IMAGE_W, IMAGE_W))))\n",
    "\n",
    "gen_features = lasagne.layers.get_output(layers.values(), generated_image)\n",
    "gen_features = {k: v for k, v in zip(layers.keys(), gen_features)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the overall loss / badness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "# content loss\n",
    "cl = 10 /1000.\n",
    "losses.append(cl * content_loss(photo_features, gen_features, 'inception_4b/output'))\n",
    "\n",
    "# style loss\n",
    "sl = 20 *1000.\n",
    "losses.append(sl * style_loss(art_features, gen_features, 'conv1/7x7_s2'))\n",
    "losses.append(sl * style_loss(art_features, gen_features, 'conv2/3x3'))\n",
    "losses.append(sl * style_loss(art_features, gen_features, 'inception_3b/output'))\n",
    "losses.append(sl * style_loss(art_features, gen_features, 'inception_4d/output'))\n",
    "#losses.append(sl * style_loss(art_features, gen_features, 'inception_5b/output'))\n",
    "\n",
    "# total variation penalty\n",
    "vp = 0.01 /1000. /1000.\n",
    "losses.append(vp * total_variation_loss(generated_image))\n",
    "\n",
    "total_loss = sum(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *Famous* Symbolic Gradient operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grad = T.grad(total_loss, generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Ready for Optimisation by SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Theano functions to evaluate loss and gradient - takes around 1 minute (!)\n",
    "f_loss = theano.function([], total_loss)\n",
    "f_grad = theano.function([], grad)\n",
    "\n",
    "# Helper functions to interface with scipy.optimize\n",
    "def eval_loss(x0):\n",
    "    x0 = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x0)\n",
    "    return f_loss().astype('float64')\n",
    "\n",
    "def eval_grad(x0):\n",
    "    x0 = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x0)\n",
    "    return np.array(f_grad()).flatten().astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize with the original ```photo```, since going from noise (the code that's commented out) takes many more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_image.set_value(photo)\n",
    "#generated_image.set_value(floatX(np.random.uniform(-128, 128, (1, 3, IMAGE_W, IMAGE_W))))\n",
    "\n",
    "x0 = generated_image.get_value().astype('float64')\n",
    "iteration=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize all those losses, and show the image\n",
    "\n",
    "To refine the result, just keep hitting 'run' on this cell (each iteration is about 60 seconds) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "scipy.optimize.fmin_l_bfgs_b(eval_loss, x0.flatten(), fprime=eval_grad, maxfun=40) \n",
    "\n",
    "x0 = generated_image.get_value().astype('float64')\n",
    "iteration += 1\n",
    "\n",
    "if False:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(googlenet.deprocess(x0), interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.text(270, 25, '# {} in {:.1f}sec'.format(iteration, (float(time.time() - t0))), fontsize=14)\n",
    "else:\n",
    "    plot_layout(googlenet.deprocess(x0))\n",
    "    print('Iteration {}, ran in {:.1f}sec'.format(iteration, float(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
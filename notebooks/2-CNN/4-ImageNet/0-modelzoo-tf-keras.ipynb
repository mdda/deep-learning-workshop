{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Sizing for Keras CNN Model Zoo\n",
    "\n",
    "This is a sanity check for : https://culurciello.github.io/tech/2016/06/04/nets.html\n",
    "\n",
    "In particular, their model comparison graph :\n",
    "\n",
    "![model comparison graph](./images/presentation/ImageNet-model-comparison_726x458.png)\n",
    "\n",
    "and this recent blog post (which came out well after this notebook was built) : http://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "#import tensorflow.contrib.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    import os, sys\n",
    "\n",
    "    targz = \"v0.5.tar.gz\"\n",
    "    url = \"https://github.com/fchollet/deep-learning-models/archive/\"+targz\n",
    "    models_orig_dir = 'deep-learning-models-0.5'\n",
    "    models_here_dir = 'keras_deep_learning_models'\n",
    "    models_dir = './models/'\n",
    "\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "\n",
    "    if not os.path.isfile( os.path.join(models_dir, models_here_dir, 'README.md') ):\n",
    "        tarfilepath = os.path.join(models_dir, targz)\n",
    "        if not os.path.isfile(tarfilepath):\n",
    "            import urllib.request \n",
    "            urllib.request.urlretrieve(url, tarfilepath) \n",
    "        import tarfile, shutil\n",
    "        tarfile.open(tarfilepath, 'r:gz').extractall(models_dir)\n",
    "        shutil.move(os.path.join(models_dir, models_orig_dir), os.path.join(models_dir, models_here_dir))\n",
    "        if os.path.isfile( os.path.join(models_dir, models_here_dir, 'README.md') ):\n",
    "            os.unlink(tarfilepath)\n",
    "\n",
    "    sys.path.append(models_dir)\n",
    "\n",
    "    print(\"Keras Model Zoo model code installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dir(keras)\n",
    "dir(keras.applications)\n",
    "#keras.__package__\n",
    "\n",
    "#import keras\n",
    "#if keras.__version__ < '2.0.0':\n",
    "#    print(\"keras version = %s is too old\" % (keras.__version__,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import decode_predictions\n",
    "from keras.preprocessing import image as keras_preprocessing_image\n",
    "\n",
    "#from keras_deep_learning_models.imagenet_utils import decode_predictions\n",
    "\n",
    "#from tensorflow.contrib.keras.api.keras.applications.inception_v3 import decode_predictions\n",
    "#from tensorflow.contrib.keras.api.keras.preprocessing import image as keras_preprocessing_image\n",
    "\n",
    "# This call to 'decode_predictions' wiil potentially download imagenet_class_index.json (35Kb)\n",
    "decode_predictions(np.zeros( (1,1000) ), top=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_to_input(model, preprocess_input_fn, img_path):\n",
    "    target_size=model.input_shape[1:]\n",
    "    img = keras_preprocessing_image.load_img(img_path, target_size=target_size)\n",
    "    \n",
    "    x = keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input_fn(x)\n",
    "    return x\n",
    "\n",
    "def test_model_sanity(model, preprocess_input_fn, img_path, img_class_str=''):\n",
    "    x = image_to_input(model, preprocess_input_fn, img_path)\n",
    "    \n",
    "    preds = model.predict(x)\n",
    "    predictions = decode_predictions(preds, top=1)\n",
    "    \n",
    "    if len(img_class_str)>0:\n",
    "        if predictions[0][0][1] != img_class_str:\n",
    "            print(\"INCORRECT CLASS!\")\n",
    "        print('Predicted:', predictions)\n",
    "        # prints: [[('n02123045', 'tabby', 0.76617092)]]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path, img_class = './images/cat-with-tongue_224x224.jpg', 'tabby'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading / timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def load_model_weights(fn, weight_set, assume_download=30):\n",
    "    t0 = time.time()\n",
    "    m = fn(weights=weight_set)\n",
    "    if time.time()-t0>float(assume_download): # more that this => downloading, so retry to get set-up time cleanly\n",
    "        print(\"Assume that >30secs means that we just downloaded the dataset : load again for timing\")        \n",
    "        t0 = time.time()\n",
    "        m = fn(weights=weight_set)\n",
    "    time_load = float(time.time()-t0)\n",
    "    weight_count=[ float(np.sum([keras.backend.count_params(p) for p in set(w)]))/1000./1000. \n",
    "                   for w in [m.trainable_weights, m.non_trainable_weights] ]\n",
    "    print(\"Loaded %.0fMM parameters (and %.0fk fixed parameters) into model in %.3f seconds\" % \n",
    "          (weight_count[0], weight_count[1]*1000., time_load,))\n",
    "    return m, time_load, weight_count[0], weight_count[1]\n",
    "\n",
    "def time_model_predictions(model, preprocess_input_fn, img_path, batch_size=1, iters=1):\n",
    "    x = image_to_input(model, preprocess_input_fn, img_path)\n",
    "\n",
    "    batch = np.tile(x, (batch_size,1,1,1))\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for i in range(iters):\n",
    "        _ = model.predict(batch,  batch_size=batch_size)\n",
    "        \n",
    "    single = float(time.time()-t0)*1000./iters/batch_size\n",
    "    print(\"A single image forward pass takes %.0f ms (in batches of %d, average of %d passes)\" % \n",
    "          (single, batch_size, iters,))\n",
    "    return single\n",
    "\n",
    "def total_summary(fn, preprocess_input_fn):\n",
    "    model, time_setup, trainable, fixed = load_model_weights(fn, 'imagenet')\n",
    "    test_model_sanity(model, preprocess_input_fn, img_path, img_class)\n",
    "    time_iter_ms = time_model_predictions(model, preprocess_input_fn, img_path, batch_size=8, iters=2)\n",
    "    model=None # Clean up\n",
    "    keras.backend.clear_session()\n",
    "    return dict(name=fn.__name__, \n",
    "                params_trainable=trainable, params_fixed=fixed, \n",
    "                time_setup=time_setup, time_iter_ms=time_iter_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worked Example : ResNet 50\n",
    "\n",
    "http://felixlaumon.github.io/2015/01/08/kaggle-right-whale.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "#from tensorflow.contrib.keras.api.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "#model_resnet50 = ResNet50(weights='imagenet')\n",
    "model_resnet50,_,_,_ = load_model_weights(ResNet50, 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model_sanity(model_resnet50, preprocess_input, img_path, img_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = time_model_predictions(model_resnet50, preprocess_input, img_path, batch_size=8, iters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_resnet50=None           # release 'pointers'\n",
    "keras.backend.clear_session() # release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate = ['VGG16', 'InceptionV3', 'ResNet50', 'Xception', 'MobileNet', '#NotThisOne'] # remove the '#' to enable\n",
    "stats_arr=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'VGG16' in evaluate:\n",
    "    from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "    #from tensorflow.contrib.keras.api.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "    stats_arr.append( total_summary( VGG16, preprocess_input ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'InceptionV3' in evaluate:\n",
    "    from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "    #from tensorflow.contrib.keras.api.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "    stats_arr.append( total_summary( InceptionV3, preprocess_input ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'ResNet50' in evaluate:\n",
    "    from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "    #from tensorflow.contrib.keras.api.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "    stats_arr.append( total_summary( ResNet50, preprocess_input ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'Xception' in evaluate:\n",
    "    from keras.applications.xception import Xception, preprocess_input\n",
    "    #from tensorflow.contrib.keras.api.keras.applications.xception import Xception, preprocess_input\n",
    "    stats_arr.append( total_summary( Xception, preprocess_input ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'MobileNet' in evaluate:\n",
    "    from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "    #from tensorflow.contrib.keras.api.keras.applications.mobilenet import ResNet50, preprocess_input\n",
    "    stats_arr.append( total_summary( MobileNet, preprocess_input ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats = { s['name']:{ k:int(v*100)/100. for k,v in s.items() if k!='name'} \n",
    "         for s in sorted(stats_arr,key=lambda x:x['name']) }\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Default Stats as a fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(stats_arr)==0:\n",
    "    stats_laptop_cpu={ # Updated 24-Aug-2017\n",
    "        'InceptionV3': {'params_fixed':    0.03,'params_trainable':  23.81,\n",
    "                        'time_iter_ms':  642.46,'time_setup':  5.14},\n",
    "        'MobileNet':   {'params_fixed':    0.02,'params_trainable':   4.23,\n",
    "                        'time_iter_ms':  199.83,'time_setup': 21.46},\n",
    "        'ResNet50':    {'params_fixed':    0.05,'params_trainable':  25.58,\n",
    "                        'time_iter_ms':  573.89,'time_setup':  3.55},\n",
    "        'VGG16':       {'params_fixed':    0.0 ,'params_trainable': 138.35,\n",
    "                        'time_iter_ms': 1021.81,'time_setup':  2.73},\n",
    "        'Xception':    {'params_fixed':    0.05,'params_trainable':  22.85,\n",
    "                        'time_iter_ms': 1193.36,'time_setup':  2.61}.\n",
    "    }\n",
    "    stats_titanx={  # Updated 24-Aug-2017\n",
    "        'InceptionV3':{ 'params_fixed':  0.03, 'params_trainable': 23.82,\n",
    "                        'time_iter_ms': 10.04, 'time_setup': 3.39},\n",
    "        'MobileNet':  { 'params_fixed':  0.02, 'params_trainable': 4.23,\n",
    "                        'time_iter_ms':  2.82, 'time_setup': 1.19},\n",
    "        'ResNet50':   { 'params_fixed':  0.05, 'params_trainable': 25.58,\n",
    "                        'time_iter_ms':  6.41, 'time_setup': 2.66},\n",
    "        'VGG16':      { 'params_fixed':  0.00, 'params_trainable': 138.36,\n",
    "                        'time_iter_ms':  6.40, 'time_setup': 0.53},\n",
    "        'Xception':   { 'params_fixed':  0.05, 'params_trainable': 22.86,\n",
    "                        'time_iter_ms': 11.29, 'time_setup': 1.90},\n",
    "    }\n",
    "    \n",
    "    stats = stats_titanx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Graph (v. different axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('image processing time (ms)')\n",
    "ax.set_ylabel('# of parameters')\n",
    "\n",
    "X,Y,R,names=[],[],[],[]\n",
    "for name, data in stats.items():\n",
    "    X.append(data['time_iter_ms'])\n",
    "    Y.append(data['params_trainable']+data['params_fixed'])\n",
    "    R.append(data['time_setup']*10.)\n",
    "    names.append(name)\n",
    "ax.scatter(X, Y, s=R)\n",
    "\n",
    "for name,x,y in zip(names, X, Y):\n",
    "    plt.annotate(\n",
    "        name, xy=(x, y), xytext=(+0, 30),\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! ls -sh ~/.keras/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " 36K imagenet_class_index.json\n",
    " 26M inception_v1_weights_tf_dim_ordering_tf_kernels.h5\n",
    " 92M inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
    " 17M mobilenet_1_0_224_tf.h5\n",
    " 99M resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
    "528M vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
    " 88M xception_weights_tf_dim_ordering_tf_kernels.h5```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "http://joelouismarino.github.io/blog_posts/blog_googlenet_keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Art Style Transfer\n",
    "\n",
    "This notebook is an implementation of the algorithm described in \"A Neural Algorithm of Artistic Style\" (http://arxiv.org/abs/1508.06576) by Gatys, Ecker and Bethge. Additional details of their method are available at http://arxiv.org/abs/1505.07376 and https://bethgelab.org/deepneuralart/.\n",
    "\n",
    "An image is generated which combines the content of a photograph with the \"style\" of a painting. This is accomplished by jointly minimizing the squared difference between feature activation maps of the photo and generated image, and the squared difference of feature correlation between painting and generated image. A total variation penalty is also applied to reduce high frequency noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#import skimage.transform\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VGG-19, 19-layer model from the paper:\n",
    "# \"Very Deep Convolutional Networks for Large-Scale Image Recognition\"\n",
    "# Original source: https://gist.github.com/ksimonyan/3785162f95cd2d5fee77\n",
    "# License: non-commercial use only\n",
    "\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer\n",
    "#from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "\n",
    "IMAGE_W = 224\n",
    "\n",
    "# Note: tweaked to use average pooling instead of maxpooling\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((1, 3, IMAGE_W, IMAGE_W))\n",
    "    net['conv1_1'] = ConvLayer(net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2, mode='average_exc_pad')\n",
    "    net['conv2_1'] = ConvLayer(net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2, mode='average_exc_pad')\n",
    "    net['conv3_1'] = ConvLayer(net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_4'] = ConvLayer(net['conv3_3'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_4'], 2, mode='average_exc_pad')\n",
    "    net['conv4_1'] = ConvLayer(net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_4'] = ConvLayer(net['conv4_3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_4'], 2, mode='average_exc_pad')\n",
    "    net['conv5_1'] = ConvLayer(net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_4'] = ConvLayer(net['conv5_3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_4'], 2, mode='average_exc_pad')\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the normalized pretrained weights from:\n",
    "# https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg19_normalized.pkl\n",
    "# (original source: https://bethgelab.org/deepneuralart/)\n",
    "\n",
    "# !wget https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg19_normalized.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build VGG net and load weights\n",
    "\n",
    "net = build_model()\n",
    "\n",
    "values = pickle.load(open('./data/VGG/vgg19_normalized.pkl'))['param values']\n",
    "lasagne.layers.set_all_param_values(net['pool5'], values)\n",
    "\n",
    "print(\"Loaded Model parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "\n",
    "def prep_image(im):\n",
    "    if len(im.shape) == 2:\n",
    "        im = im[:, :, np.newaxis]\n",
    "        im = np.repeat(im, 3, axis=2)\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        #im = skimage.transform.resize(im, (IMAGE_W, w*IMAGE_W/h), preserve_range=True)\n",
    "        im = scipy.misc.imresize(im, (IMAGE_W, w*IMAGE_W/h))\n",
    "    else:\n",
    "        #im = skimage.transform.resize(im, (h*IMAGE_W/w, IMAGE_W), preserve_range=True)\n",
    "        im = scipy.misc.imresize(im, (h*IMAGE_W/w, IMAGE_W))\n",
    "\n",
    "    # Central crop\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-IMAGE_W//2:h//2+IMAGE_W//2, w//2-IMAGE_W//2:w//2+IMAGE_W//2]\n",
    "    \n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # Convert RGB to BGR\n",
    "    im = im[::-1, :, :]\n",
    "\n",
    "    im = im - MEAN_VALUES\n",
    "    return rawim, floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "photo = plt.imread('./images/art-style/Tuebingen_Neckarfront.jpg')\n",
    "rawim, photo = prep_image(photo)\n",
    "plt.imshow(rawim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "art = plt.imread('./images/art-style/960px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg')\n",
    "rawim, art = prep_image(art)\n",
    "plt.imshow(rawim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    x = x.flatten(ndim=3)\n",
    "    g = T.tensordot(x, x, axes=([2], [2]))\n",
    "    return g\n",
    "\n",
    "\n",
    "def content_loss(P, X, layer):\n",
    "    p = P[layer]\n",
    "    x = X[layer]\n",
    "    \n",
    "    loss = 1./2 * ((x - p)**2).sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def style_loss(A, X, layer):\n",
    "    a = A[layer]\n",
    "    x = X[layer]\n",
    "    \n",
    "    A = gram_matrix(a)\n",
    "    G = gram_matrix(x)\n",
    "    \n",
    "    N = a.shape[1]\n",
    "    M = a.shape[2] * a.shape[3]\n",
    "    \n",
    "    loss = 1./(4 * N**2 * M**2) * ((G - A)**2).sum()\n",
    "    return loss\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    return (((x[:,:,:-1,:-1] - x[:,:,1:,:-1])**2 + (x[:,:,:-1,:-1] - x[:,:,:-1,1:])**2)**1.25).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = ['conv4_2', 'conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "layers = {k: net[k] for k in layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Precompute layer activations for photo and artwork\n",
    "input_im_theano = T.tensor4()\n",
    "outputs = lasagne.layers.get_output(layers.values(), input_im_theano)\n",
    "\n",
    "photo_features = {k: theano.shared(output.eval({input_im_theano: photo}))\n",
    "                  for k, output in zip(layers.keys(), outputs)}\n",
    "art_features = {k: theano.shared(output.eval({input_im_theano: art}))\n",
    "                for k, output in zip(layers.keys(), outputs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get expressions for layer activations for generated image\n",
    "generated_image = theano.shared(floatX(np.random.uniform(-128, 128, (1, 3, IMAGE_W, IMAGE_W))))\n",
    "\n",
    "gen_features = lasagne.layers.get_output(layers.values(), generated_image)\n",
    "gen_features = {k: v for k, v in zip(layers.keys(), gen_features)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "losses = []\n",
    "\n",
    "# content loss\n",
    "losses.append(0.001 * content_loss(photo_features, gen_features, 'conv4_2'))\n",
    "\n",
    "# style loss\n",
    "losses.append(0.2e6 * style_loss(art_features, gen_features, 'conv1_1'))\n",
    "losses.append(0.2e6 * style_loss(art_features, gen_features, 'conv2_1'))\n",
    "losses.append(0.2e6 * style_loss(art_features, gen_features, 'conv3_1'))\n",
    "losses.append(0.2e6 * style_loss(art_features, gen_features, 'conv4_1'))\n",
    "losses.append(0.2e6 * style_loss(art_features, gen_features, 'conv5_1'))\n",
    "\n",
    "# total variation penalty\n",
    "losses.append(0.1e-7 * total_variation_loss(generated_image))\n",
    "\n",
    "total_loss = sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grad = T.grad(total_loss, generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Theano functions to evaluate loss and gradient\n",
    "f_loss = theano.function([], total_loss)\n",
    "f_grad = theano.function([], grad)\n",
    "\n",
    "# Helper functions to interface with scipy.optimize\n",
    "def eval_loss(x0):\n",
    "    x0 = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x0)\n",
    "    return f_loss().astype('float64')\n",
    "\n",
    "def eval_grad(x0):\n",
    "    x0 = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x0)\n",
    "    return np.array(f_grad()).flatten().astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize with a noise image\n",
    "generated_image.set_value(floatX(np.random.uniform(-128, 128, (1, 3, IMAGE_W, IMAGE_W))))\n",
    "\n",
    "x0 = generated_image.get_value().astype('float64')\n",
    "xs = []\n",
    "xs.append(x0)\n",
    "\n",
    "# Optimize, saving the result periodically\n",
    "for i in range(8):\n",
    "    print(i)\n",
    "    #scipy.optimize.fmin_l_bfgs_b(eval_loss, x0.flatten(), fprime=eval_grad, maxfun=40)\n",
    "    scipy.optimize.fmin_l_bfgs_b(eval_loss, x0.flatten(), fprime=eval_grad, maxfun=7)  # same as Keras\n",
    "    x0 = generated_image.get_value().astype('float64')\n",
    "    xs.append(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deprocess(x):\n",
    "    x = np.copy(x[0])\n",
    "    x += MEAN_VALUES\n",
    "\n",
    "    x = x[::-1]\n",
    "    x = np.swapaxes(np.swapaxes(x, 0, 1), 1, 2)\n",
    "    \n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.gca().xaxis.set_visible(False)    \n",
    "    plt.gca().yaxis.set_visible(False)    \n",
    "    plt.imshow(deprocess(xs[i]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(deprocess(xs[-1]), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
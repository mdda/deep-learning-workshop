{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Purposing a Pretrained Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "This notebook extracts a vector representation of a set of images using the GoogLeNet CNN pretrained on ImageNet.  It then builds a classifier, so that new images can be classified directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "CLASS_DIR='./images/cars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for building the GoogLeNet model with Lasagne and preprocessing the images are defined in model.googlenet.\n",
    "\n",
    "Build the model and select layers we need - the features are taken from the final network layer, before the softmax nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import googlenet\n",
    "\n",
    "cnn_layers = googlenet.build_model()\n",
    "cnn_input_var = cnn_layers['input'].input_var\n",
    "cnn_feature_layer = cnn_layers['loss3/classifier']\n",
    "cnn_output_layer = cnn_layers['prob']\n",
    "\n",
    "get_cnn_features = theano.function([cnn_input_var], lasagne.layers.get_output(cnn_feature_layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained weights into the network :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = pickle.load(open('./data/googlenet/blvc_googlenet.pkl'))\n",
    "model_param_values = params['param values']\n",
    "imagenet_classes = params['synset words']\n",
    "lasagne.layers.set_all_param_values(cnn_output_layer, model_param_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Network to create 'features' for the training images\n",
    "\n",
    "Now go through the input images and feature-ize them according to the pretrained network.\n",
    "\n",
    "NB: The pretraining was done on ImageNet - there wasn't anything specific to the recognition task we're doing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "classes = sorted( [ d for d in os.listdir(CLASS_DIR) if os.path.isdir(\"%s/%s\" % (CLASS_DIR, d)) ] )\n",
    "classes # Sorted for for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = dict(f=[], features=[], target=[])\n",
    "\n",
    "t0 = time.time()\n",
    "for class_i,d in enumerate(classes):\n",
    "    for f in os.listdir(\"%s/%s\" % (CLASS_DIR, d,)):\n",
    "        filepath = '%s/%s/%s' % (CLASS_DIR,d,f,)\n",
    "        if os.path.isdir(filepath): continue\n",
    "        im = plt.imread(filepath)\n",
    "        rawim, cnn_im = googlenet.prep_image(im)\n",
    "\n",
    "        prob = get_cnn_features(cnn_im)\n",
    "\n",
    "        train['f'].append(filepath)\n",
    "        train['features'].append(prob[0])\n",
    "        train['target'].append( class_i )\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(rawim.astype('uint8'))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.text(320, 50, '{}'.format(f), fontsize=14)\n",
    "        plt.text(320, 80, 'Train as class \"{}\"'.format(d), fontsize=12)\n",
    "    \n",
    "print(\"DONE : %6.2f seconds each\" %(float(time.time() - t0)/len(train),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build an SVM model over the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(train['features'], train['target']) # learn from the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Use the SVM model to classify the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_image_files = [f for f in os.listdir(CLASS_DIR) if not os.path.isdir(\"%s/%s\" % (CLASS_DIR, f))]\n",
    "\n",
    "t0 = time.time()\n",
    "for f in sorted(test_image_files):\n",
    "    im = plt.imread('%s/%s' % (CLASS_DIR,f,))\n",
    "    rawim, cnn_im = googlenet.prep_image(im)\n",
    "        \n",
    "    prob = get_cnn_features(cnn_im)\n",
    "\n",
    "    prediction_i = classifier.predict([ prob[0] ])\n",
    "    decision     = classifier.decision_function([ prob[0] ])\n",
    "                       \n",
    "    plt.figure()\n",
    "    plt.imshow(rawim.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "                \n",
    "    prediction = classes[ prediction_i[0] ]\n",
    "                       \n",
    "    plt.text(350, 50, '{} : Distance from boundary = {:5.2f}'.format(prediction, decision[0]), fontsize=20)\n",
    "    plt.text(350, 75, '{}'.format(f), fontsize=14)\n",
    "    \n",
    "print(\"DONE : %6.2f seconds each\" %(float(time.time() - t0)/len(test_image_files),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try your own ideas\n",
    "\n",
    "The whole training regime here is based on the way the image directories are structured.  So building your own example shouldn't be very difficult.\n",
    "\n",
    "Suppose you wanted to classify pianos into Upright and Grand : \n",
    "\n",
    "*  Create a ```pianos``` directory and point the ```CLASS_DIR``` variable at it\n",
    "*  Within the ```pianos``` directory, create subdirectories for each of the classes (i.e. ```Upright``` and ```Grand```).  The directory names will be used as the class labels\n",
    "*  Inside the class directories, put a 'bunch' of positive examples of the respective classes - these can be images in any reasonable format, of any size (above 224x224).\n",
    "   +  The images will be automatically resized so that their smallest dimension is 224, and then a square 'crop' area taken from their centers (since ImageNet networks are typically tuned to answering on 224x224 images)\n",
    "*  Test images should be put in ```pianos``` itelf (which is logical, since we don't *know* their classes yet)\n",
    "\n",
    "Finally, re-run everything - checking that the training images are read in correctly, that there are no errors along the way, and that (finally) the class predictions on the test set come out as expected.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}